{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RydCRCp7Q7YD",
        "uurzjp7fQ-2W"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb659f3e50024c13acdf9aa0be6c085e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3e5e2d50d1834c5cab2df25e8e1572f6",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m   8%\u001b[0m \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84,940/1,000,000 \u001b[0m [ \u001b[33m0:02:50\u001b[0m < \u001b[36m0:35:35\u001b[0m , \u001b[31m429 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">   8%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">84,940/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:02:50</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:35:35</span> , <span style=\"color: #800000; text-decoration-color: #800000\">429 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "3e5e2d50d1834c5cab2df25e8e1572f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3[extra]"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWy2DpcrMJal",
        "outputId": "85aabb3b-dc88-419d-a029-df699d049456"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable_baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (2.17.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (11.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py>=0.9.0->stable_baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable_baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable_baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable_baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable_baselines3[extra]) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/metadriverse/metadrive.git"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc2-5R5BMQ_9",
        "outputId": "5b2e1dd8-d8c8-4bbf-fe49-6cebce544edc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/metadriverse/metadrive.git\n",
            "  Cloning https://github.com/metadriverse/metadrive.git to /tmp/pip-req-build-opao1mip\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/metadriverse/metadrive.git /tmp/pip-req-build-opao1mip\n",
            "  Resolved https://github.com/metadriverse/metadrive.git to commit 295a89375ff0f883c3f58f9ade8869f6ee8625d9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (2.32.3)\n",
            "Requirement already satisfied: gymnasium>=0.28 in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (3.8.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (2.6.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (0.43.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (4.67.1)\n",
            "Requirement already satisfied: progressbar in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (2.5)\n",
            "Requirement already satisfied: panda3d==1.10.14 in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (1.10.14)\n",
            "Requirement already satisfied: panda3d-gltf==0.13 in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (0.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (11.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (4.10.0.84)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (5.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (1.13.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (5.9.5)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (2.0.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (3.16.1)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (2.18.0)\n",
            "Requirement already satisfied: mediapy in /usr/local/lib/python3.10/dist-packages (from metadrive-simulator==0.4.3) (1.2.2)\n",
            "Requirement already satisfied: panda3d-simplepbr>=0.6 in /usr/local/lib/python3.10/dist-packages (from panda3d-gltf==0.13->metadrive-simulator==0.4.3) (0.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (2.8.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from mediapy->metadrive-simulator==0.4.3) (7.34.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->metadrive-simulator==0.4.3) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->metadrive-simulator==0.4.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->metadrive-simulator==0.4.3) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->metadrive-simulator==0.4.3) (2024.12.14)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->metadrive-simulator==0.4.3) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->metadrive-simulator==0.4.3) (2.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->metadrive-simulator==0.4.3) (1.17.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->mediapy->metadrive-simulator==0.4.3) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->mediapy->metadrive-simulator==0.4.3) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy->metadrive-simulator==0.4.3) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RL Environment"
      ],
      "metadata": {
        "id": "RydCRCp7Q7YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from metadrive.envs.safe_metadrive_env import SafeMetaDriveEnv\n",
        "\n",
        "DEFAULT_CONFIG = {\n",
        "    # The below are default configs copied from SafeMetaDriveEnv\n",
        "    # Environment difficulty\n",
        "    \"accident_prob\": 0.8,\n",
        "    \"traffic_density\": 0.05,\n",
        "    # Termination conditions\n",
        "    \"crash_vehicle_done\": False,\n",
        "    \"crash_object_done\": False,\n",
        "    # Reward\n",
        "    \"success_reward\": 10.0,\n",
        "    \"driving_reward\": 1.0,\n",
        "    \"speed_reward\": 0.1,\n",
        "    # Penalty will be negated and added to reward\n",
        "    \"out_of_road_penalty\": 5.0,\n",
        "    \"crash_vehicle_penalty\": 1.0,\n",
        "    \"crash_object_penalty\": 1.0,\n",
        "    # Cost will be return in info[\"cost\"] and you can do constrained optimization with it\n",
        "    \"crash_vehicle_cost\": 1.0,\n",
        "    \"crash_object_cost\": 1.0,\n",
        "    \"out_of_road_cost\": 1.0,\n",
        "}\n",
        "\n",
        "# Use deepcopy to avoid modifying the DEFAULT_CONFIG\n",
        "TRAINING_CONFIG = copy.deepcopy(DEFAULT_CONFIG)\n",
        "TRAINING_CONFIG.update(\n",
        "    {  # Environment setting\n",
        "        \"num_scenarios\": 50,  # There are totally 50 possible maps.\n",
        "        \"start_seed\": 100,  # We will use the map with seeds in [100, 150) as the default training environment.\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "def get_training_env(extra_config=None):\n",
        "    config = copy.deepcopy(TRAINING_CONFIG)\n",
        "    if extra_config:\n",
        "        config.update(extra_config)\n",
        "    return SafeMetaDriveEnv(config)\n",
        "\n",
        "\n",
        "VALIDATION_CONFIG = copy.deepcopy(DEFAULT_CONFIG)\n",
        "VALIDATION_CONFIG.update(\n",
        "    {  # Environment setting\n",
        "        \"num_scenarios\": 50,  # There are totally 50 possible maps.\n",
        "        \"start_seed\": 1000,  # We will use the map with seeds in [1000, 1050) as the default validation environment.\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "def get_validation_env(extra_config=None):\n",
        "    config = copy.deepcopy(VALIDATION_CONFIG)\n",
        "    if extra_config:\n",
        "        config.update(extra_config)\n",
        "    return SafeMetaDriveEnv(config)\n"
      ],
      "metadata": {
        "id": "fFBku609MWPU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and utilities"
      ],
      "metadata": {
        "id": "uurzjp7fQ-2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import datetime\n",
        "import logging\n",
        "import os\n",
        "import uuid\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from metadrive.engine.logger import set_log_level\n",
        "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "from stable_baselines3.ppo import PPO\n",
        "from stable_baselines3.ppo.policies import ActorCriticPolicy\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "# Remove MetaDrive's logging information when episode ends.\n",
        "set_log_level(logging.ERROR)"
      ],
      "metadata": {
        "id": "gIfW6RQSMGmk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_time_str():\n",
        "    return datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "\n",
        "def remove_reset_seed_and_add_monitor(make_env, trial_dir):\n",
        "    \"\"\"\n",
        "    MetaDrive env's reset function takes a seed argument and use it to determine the map to load.\n",
        "    However, in stable-baselines3, it calls reset function with a seed argument serving as the random seed,\n",
        "    which is not what we want. We do a trick here to remap the random seed to map index.\n",
        "\n",
        "    Stable-baselines3 recommends using Monitor wrapper to log training data. We add a Monitor wrapper here.\n",
        "    \"\"\"\n",
        "    from gymnasium import Wrapper\n",
        "    from stable_baselines3.common.monitor import Monitor\n",
        "    class NewClass(Wrapper):\n",
        "        def reset(self, seed=None, **kwargs):\n",
        "            # PZH: We do a trick here to remap the seed to the map index. This can help randomize the maps.\n",
        "            if seed is not None:\n",
        "                new_seed = self.env.start_index + (seed % self.env.num_scenarios)\n",
        "            else:\n",
        "                new_seed = None\n",
        "            return self.env.reset(seed=new_seed, **kwargs)\n",
        "\n",
        "    def new_make_env():\n",
        "        env = make_env()\n",
        "        NewClass.__name__ = env.__class__.__name__ + \"WithoutResetSeed\"\n",
        "        wrapped_env = NewClass(env)\n",
        "        wrapped_env = Monitor(env=wrapped_env, filename=str(trial_dir))\n",
        "        return wrapped_env\n",
        "\n",
        "    return new_make_env\n",
        "\n",
        "\n",
        "class CustomizedEvalCallback(EvalCallback):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.evaluations_info_buffer = defaultdict(list)\n",
        "\n",
        "    def _log_success_callback(self, locals_, globals_):\n",
        "        info = locals_[\"info\"]\n",
        "\n",
        "        if locals_[\"done\"]:\n",
        "            maybe_is_success = info.get(\"is_success\")\n",
        "            if maybe_is_success is not None:\n",
        "                self._is_success_buffer.append(maybe_is_success)\n",
        "\n",
        "            maybe_is_success2 = info.get(\"arrive_dest\", None)\n",
        "            if maybe_is_success2 is not None:\n",
        "                self._is_success_buffer.append(maybe_is_success2)\n",
        "\n",
        "            assert (maybe_is_success is None) or (maybe_is_success2 is None), \"We cannot have two success flags!\"\n",
        "\n",
        "            for k in [\"route_completion\", \"total_cost\", \"arrive_dest\", \"max_step\", \"out_of_road\", \"crash\"]:\n",
        "                if k in info:\n",
        "                    self.evaluations_info_buffer[k].append(info[k])\n",
        "\n",
        "        if \"raw_action\" in info:\n",
        "            self.evaluations_info_buffer[\"raw_action\"].append(info[\"raw_action\"])\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        \"\"\"\n",
        "        PZH Note: Overall this function is copied from original EvalCallback._on_step.\n",
        "        We additionally record evaluations_info_buffer to the logger.\n",
        "        \"\"\"\n",
        "\n",
        "        from stable_baselines3.common.evaluation import evaluate_policy\n",
        "        from stable_baselines3.common.vec_env import sync_envs_normalization\n",
        "\n",
        "        continue_training = True\n",
        "\n",
        "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "            # Sync training and eval env if there is VecNormalize\n",
        "            if self.model.get_vec_normalize_env() is not None:\n",
        "                try:\n",
        "                    sync_envs_normalization(self.training_env, self.eval_env)\n",
        "                except AttributeError as e:\n",
        "                    raise AssertionError(\n",
        "                        \"Training and eval env are not wrapped the same way, \"\n",
        "                        \"see https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html#evalcallback \"\n",
        "                        \"and warning above.\"\n",
        "                    ) from e\n",
        "\n",
        "            # Reset success rate buffer\n",
        "            self._is_success_buffer = []\n",
        "\n",
        "            episode_rewards, episode_lengths = evaluate_policy(\n",
        "                self.model,\n",
        "                self.eval_env,\n",
        "                n_eval_episodes=self.n_eval_episodes,\n",
        "                render=self.render,\n",
        "                deterministic=self.deterministic,\n",
        "                return_episode_rewards=True,\n",
        "                warn=self.warn,\n",
        "                callback=self._log_success_callback,\n",
        "            )\n",
        "\n",
        "            if self.log_path is not None:\n",
        "                assert isinstance(episode_rewards, list)\n",
        "                assert isinstance(episode_lengths, list)\n",
        "                self.evaluations_timesteps.append(self.num_timesteps)\n",
        "                self.evaluations_results.append(episode_rewards)\n",
        "                self.evaluations_length.append(episode_lengths)\n",
        "\n",
        "                kwargs = {}\n",
        "                # Save success log if present\n",
        "                if len(self._is_success_buffer) > 0:\n",
        "                    self.evaluations_successes.append(self._is_success_buffer)\n",
        "                    kwargs = dict(successes=self.evaluations_successes)\n",
        "\n",
        "                # PZH: Save evaluations_info_buffer to the log file\n",
        "                for k, v in self.evaluations_info_buffer.items():\n",
        "                    kwargs[k] = v\n",
        "\n",
        "                np.savez(\n",
        "                    self.log_path,\n",
        "                    timesteps=self.evaluations_timesteps,\n",
        "                    results=self.evaluations_results,\n",
        "                    ep_lengths=self.evaluations_length,\n",
        "                    **kwargs,  # type: ignore[arg-type]\n",
        "                )\n",
        "\n",
        "            mean_reward, std_reward = np.mean(episode_rewards), np.std(episode_rewards)\n",
        "            mean_ep_length, std_ep_length = np.mean(episode_lengths), np.std(episode_lengths)\n",
        "            self.last_mean_reward = float(mean_reward)\n",
        "\n",
        "            if self.verbose >= 1:\n",
        "                print(\n",
        "                    f\"Eval num_timesteps={self.num_timesteps}, \" f\"episode_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "                print(f\"Episode length: {mean_ep_length:.2f} +/- {std_ep_length:.2f}\")\n",
        "            # Add to current Logger\n",
        "            self.logger.record(\"eval/mean_reward\", float(mean_reward))\n",
        "            self.logger.record(\"eval/mean_ep_length\", mean_ep_length)\n",
        "\n",
        "            # PZH: Add this metric.\n",
        "            self.logger.record(\"eval/num_episodes\", len(episode_rewards))\n",
        "\n",
        "            if len(self._is_success_buffer) > 0:\n",
        "                success_rate = np.mean(self._is_success_buffer)\n",
        "                if self.verbose >= 1:\n",
        "                    print(f\"Success rate: {100 * success_rate:.2f}%\")\n",
        "                self.logger.record(\"eval/success_rate\", success_rate)\n",
        "\n",
        "            # PZH: We record evaluations_info_buffer to the logger\n",
        "            for k, v in self.evaluations_info_buffer.items():\n",
        "                self.logger.record(\"eval/{}\".format(k), np.mean(np.asarray(v)))\n",
        "\n",
        "            # Dump log so the evaluation results are printed with the correct timestep\n",
        "            self.logger.record(\"time/total_timesteps\", self.num_timesteps, exclude=\"tensorboard\")\n",
        "            self.logger.dump(self.num_timesteps)\n",
        "\n",
        "            if mean_reward > self.best_mean_reward:\n",
        "                if self.verbose >= 1:\n",
        "                    print(\"New best mean reward!\")\n",
        "                if self.best_model_save_path is not None:\n",
        "                    self.model.save(os.path.join(self.best_model_save_path, \"best_model\"))\n",
        "                self.best_mean_reward = float(mean_reward)\n",
        "                # Trigger callback on new best model, if needed\n",
        "                if self.callback_on_new_best is not None:\n",
        "                    continue_training = self.callback_on_new_best.on_step()\n",
        "\n",
        "            # Trigger callback after every evaluation, if needed\n",
        "            if self.callback is not None:\n",
        "                continue_training = continue_training and self._on_event()\n",
        "\n",
        "        return continue_training\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5dhUBr7MHFa",
        "outputId": "347fc799-ac88-4959-a553-fbaa340f0d0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup PPO trainer"
      ],
      "metadata": {
        "id": "YeOXgzj7RDTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===== Set up some arguments =====\n",
        "exp_name = \"ppo_metadrive\"\n",
        "use_wandb = True\n",
        "\n",
        "experiment_batch_name = \"{}\".format(exp_name)\n",
        "trial_name = \"{}_{}_{}\".format(experiment_batch_name, get_time_str(), uuid.uuid4().hex[:8])\n",
        "experiment_dir = Path(\"runs\") / experiment_batch_name\n",
        "trial_dir = experiment_dir / trial_name\n",
        "os.makedirs(experiment_dir, exist_ok=True)\n",
        "os.makedirs(trial_dir, exist_ok=True)\n",
        "print(f\"We start logging training data into {trial_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4I25BRYMltK",
        "outputId": "9a43fb4a-ec79-4625-cf6c-1a302d70fd4c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We start logging training data into runs/ppo_metadrive/ppo_metadrive_2025-02-21_06-46-27_d987f516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Setup environment =====\n",
        "num_train_envs = 10\n",
        "num_eval_envs = 5\n",
        "train_env = make_vec_env(remove_reset_seed_and_add_monitor(get_training_env, trial_dir), n_envs=num_train_envs,\n",
        "                            vec_env_cls=SubprocVecEnv)\n",
        "eval_env = make_vec_env(remove_reset_seed_and_add_monitor(get_validation_env, trial_dir), n_envs=num_eval_envs,\n",
        "                        vec_env_cls=SubprocVecEnv)"
      ],
      "metadata": {
        "id": "Yle5pkCvOQAL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Setup evaluation, checkpointing, and wandb =====\n",
        "save_freq = 10_000  # Number of steps per model checkpoint\n",
        "eval_freq = 10_000  # Number of steps per evaluation\n",
        "\n",
        "wandb_save_freq = 10_000  # Number of steps per evaluation\n",
        "\n",
        "num_eval_episodes = 5\n",
        "\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    name_prefix=\"rl_model\",\n",
        "    verbose=2,\n",
        "    save_freq=save_freq,\n",
        "    save_path=str(trial_dir / \"models\")\n",
        ")\n",
        "eval_callback = CustomizedEvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=str(trial_dir / \"eval\"),\n",
        "    log_path=str(trial_dir / \"eval\"),\n",
        "    eval_freq=max(eval_freq // num_train_envs, 1),\n",
        "    n_eval_episodes=num_eval_episodes,\n",
        ")\n",
        "callbacks = [checkpoint_callback, eval_callback]\n",
        "if use_wandb:\n",
        "    wandb.init(\n",
        "        project=\"cs260r\",\n",
        "        id=trial_name,\n",
        "        name=experiment_batch_name,\n",
        "        sync_tensorboard=True,\n",
        "        dir=str(trial_dir),\n",
        "    )\n",
        "    callbacks.append(WandbCallback(model_save_path=str(trial_dir / \"wandb_models\"), model_save_freq=wandb_save_freq))\n",
        "callbacks = CallbackList(callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "IP_wvQMBMzoR",
        "outputId": "cf93c999-e965-43bf-9407-796e3d9834e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  return LooseVersion(v) >= LooseVersion(check)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py:202: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  settings = self._wl.settings.copy()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpengzhenghao\u001b[0m (\u001b[33mdrivingforce\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>runs/ppo_metadrive/ppo_metadrive_2025-02-21_06-46-27_d987f516/wandb/run-20250221_064646-ppo_metadrive_2025-02-21_06-46-27_d987f516</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/drivingforce/cs260r/runs/ppo_metadrive_2025-02-21_06-46-27_d987f516' target=\"_blank\">ppo_metadrive</a></strong> to <a href='https://wandb.ai/drivingforce/cs260r' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/drivingforce/cs260r' target=\"_blank\">https://wandb.ai/drivingforce/cs260r</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/drivingforce/cs260r/runs/ppo_metadrive_2025-02-21_06-46-27_d987f516' target=\"_blank\">https://wandb.ai/drivingforce/cs260r/runs/ppo_metadrive_2025-02-21_06-46-27_d987f516</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===== Setup the training algorithm =====\n",
        "model = PPO(\n",
        "    env=train_env,\n",
        "    policy=ActorCriticPolicy,\n",
        "    n_steps=500,  # n_steps * n_envs = total_batch_size\n",
        "    n_epochs=20,\n",
        "    learning_rate=5e-5,\n",
        "    batch_size=256,\n",
        "    clip_range=0.1,\n",
        "    vf_coef=0.5,\n",
        "    ent_coef=0.0,\n",
        "    max_grad_norm=10.0,\n",
        "    tensorboard_log=str(trial_dir),\n",
        "    verbose=2,\n",
        "    device=\"auto\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7umQKXAMuJf",
        "outputId": "bc81df7c-411b-4266-bd3c-9ba4ae9fd8c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5000`, after every 19 untruncated mini-batches, there will be a truncated mini-batch of size 136\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=500 and n_envs=10)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = None\n",
        "if ckpt:\n",
        "    ckpt = Path(ckpt)\n",
        "    print(f\"Loading checkpoint from {ckpt}!\")\n",
        "    from stable_baselines3.common.save_util import load_from_zip_file\n",
        "    data, params, pytorch_variables = load_from_zip_file(ckpt, device=model.device, print_system_info=False)\n",
        "    model.set_parameters(params, exact_match=True, device=model.device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfnwlEiTNKeB",
        "outputId": "a3333324-7ebf-429a-f5ba-e403b92346ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Launch training =====\n",
        "total_timesteps = 1_000_000  # 1M steps\n",
        "model.learn(\n",
        "    total_timesteps=total_timesteps,\n",
        "    callback=callbacks,\n",
        "    reset_num_timesteps=True,\n",
        "    tb_log_name=experiment_batch_name,\n",
        "    log_interval=1,\n",
        "    progress_bar=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cb659f3e50024c13acdf9aa0be6c085e",
            "3e5e2d50d1834c5cab2df25e8e1572f6"
          ]
        },
        "id": "W1baXGNANOQ-",
        "outputId": "45cc778c-8a2d-447a-f5fa-166dfb127b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to runs/ppo_metadrive/ppo_metadrive_2025-02-21_06-46-27_d987f516/ppo_metadrive_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb659f3e50024c13acdf9aa0be6c085e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 412      |\n",
            "|    ep_rew_mean     | 0.267    |\n",
            "| time/              |          |\n",
            "|    fps             | 887      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 5000     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 412          |\n",
            "|    ep_rew_mean          | 0.267        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 765          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 10000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032324276 |\n",
            "|    clip_fraction        | 0.194        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0.00871      |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.0535       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00707     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 0.094        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 837          |\n",
            "|    ep_rew_mean          | 6.47         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 726          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 15000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042496137 |\n",
            "|    clip_fraction        | 0.266        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.0498       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | -0.00441     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.0142      |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 0.0153       |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=20000, episode_reward=42.54 +/- 23.19\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=20000, episode_reward=42.54 +/- 23.19\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 116.20 +/- 39.55\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 116.20 +/- 39.55\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0            |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 116          |\n",
            "|    mean_reward          | 42.5         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.13235468   |\n",
            "|    route_completion     | 0.15         |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 1            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 20000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036342829 |\n",
            "|    clip_fraction        | 0.206        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.81        |\n",
            "|    explained_variance   | -0.00715     |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.086        |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00697     |\n",
            "|    std                  | 0.985        |\n",
            "|    value_loss           | 0.108        |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 837      |\n",
            "|    ep_rew_mean     | 6.47     |\n",
            "| time/              |          |\n",
            "|    fps             | 655      |\n",
            "|    iterations      | 4        |\n",
            "|    time_elapsed    | 30       |\n",
            "|    total_timesteps | 20000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1.54e+03     |\n",
            "|    ep_rew_mean          | 18.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 644          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 38           |\n",
            "|    total_timesteps      | 25000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042506717 |\n",
            "|    clip_fraction        | 0.286        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.8         |\n",
            "|    explained_variance   | 0.0535       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.0014       |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.0162      |\n",
            "|    std                  | 0.978        |\n",
            "|    value_loss           | 0.0423       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.41e+03    |\n",
            "|    ep_rew_mean          | 20.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 628         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 47          |\n",
            "|    total_timesteps      | 30000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003264529 |\n",
            "|    clip_fraction        | 0.162       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -2.79       |\n",
            "|    explained_variance   | -0.00486    |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.021       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00421    |\n",
            "|    std                  | 0.976       |\n",
            "|    value_loss           | 0.264       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.12e+03    |\n",
            "|    ep_rew_mean          | 17.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 607         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 57          |\n",
            "|    total_timesteps      | 35000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002706751 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -2.78       |\n",
            "|    explained_variance   | 0.00904     |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.346       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00379    |\n",
            "|    std                  | 0.968       |\n",
            "|    value_loss           | 0.446       |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=40000, episode_reward=79.37 +/- 29.88\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=40000, episode_reward=79.37 +/- 29.88\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 101.20 +/- 19.93\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 101.20 +/- 19.93\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0.1          |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 101          |\n",
            "|    mean_reward          | 79.4         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.19606099   |\n",
            "|    route_completion     | 0.205        |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 1            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 40000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024198024 |\n",
            "|    clip_fraction        | 0.101        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.77        |\n",
            "|    explained_variance   | 0.00303      |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.736        |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00248     |\n",
            "|    std                  | 0.965        |\n",
            "|    value_loss           | 0.807        |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 952      |\n",
            "|    ep_rew_mean     | 16.1     |\n",
            "| time/              |          |\n",
            "|    fps             | 573      |\n",
            "|    iterations      | 8        |\n",
            "|    time_elapsed    | 69       |\n",
            "|    total_timesteps | 40000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 834          |\n",
            "|    ep_rew_mean          | 15.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 567          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 45000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017283519 |\n",
            "|    clip_fraction        | 0.0921       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.76        |\n",
            "|    explained_variance   | 0.0124       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.239        |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00256     |\n",
            "|    std                  | 0.964        |\n",
            "|    value_loss           | 0.795        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 810         |\n",
            "|    ep_rew_mean          | 16.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 564         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 88          |\n",
            "|    total_timesteps      | 50000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002067664 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -2.76       |\n",
            "|    explained_variance   | 0.0462      |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.414       |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00271    |\n",
            "|    std                  | 0.959       |\n",
            "|    value_loss           | 0.769       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 773         |\n",
            "|    ep_rew_mean          | 17.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 560         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 98          |\n",
            "|    total_timesteps      | 55000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002288449 |\n",
            "|    clip_fraction        | 0.0854      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -2.75       |\n",
            "|    explained_variance   | 0.032       |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.338       |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00256    |\n",
            "|    std                  | 0.952       |\n",
            "|    value_loss           | 0.644       |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=60000, episode_reward=58.70 +/- 5.74\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=60000, episode_reward=58.70 +/- 5.74\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 79.00 +/- 11.88\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 79.00 +/- 11.88\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0.0667       |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 79           |\n",
            "|    mean_reward          | 58.7         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.24757423   |\n",
            "|    route_completion     | 0.203        |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 1            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 60000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026677686 |\n",
            "|    clip_fraction        | 0.128        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.73        |\n",
            "|    explained_variance   | 0.0267       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 0.527        |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00458     |\n",
            "|    std                  | 0.943        |\n",
            "|    value_loss           | 1.03         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 640      |\n",
            "|    ep_rew_mean     | 15.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 537      |\n",
            "|    iterations      | 12       |\n",
            "|    time_elapsed    | 111      |\n",
            "|    total_timesteps | 60000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 609          |\n",
            "|    ep_rew_mean          | 17.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 533          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 121          |\n",
            "|    total_timesteps      | 65000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018349536 |\n",
            "|    clip_fraction        | 0.0844       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.71        |\n",
            "|    explained_variance   | 0.0264       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.25         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00307     |\n",
            "|    std                  | 0.936        |\n",
            "|    value_loss           | 2.29         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 388         |\n",
            "|    ep_rew_mean          | 16.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 523         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 133         |\n",
            "|    total_timesteps      | 70000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001716755 |\n",
            "|    clip_fraction        | 0.0598      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -2.7        |\n",
            "|    explained_variance   | 0.0306      |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.652       |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00174    |\n",
            "|    std                  | 0.931       |\n",
            "|    value_loss           | 1.75        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 330          |\n",
            "|    ep_rew_mean          | 17.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 519          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 144          |\n",
            "|    total_timesteps      | 75000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013871611 |\n",
            "|    clip_fraction        | 0.0558       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.69        |\n",
            "|    explained_variance   | 0.0234       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 2.09         |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    std                  | 0.928        |\n",
            "|    value_loss           | 2.61         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=80000, episode_reward=78.23 +/- 3.84\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=80000, episode_reward=78.23 +/- 3.84\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 77.60 +/- 1.36\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 77.60 +/- 1.36\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Success rate: 0.00%\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Success rate: 0.00%\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    arrive_dest          | 0            |\n",
            "|    crash                | 0.15         |\n",
            "|    max_step             | 0            |\n",
            "|    mean_ep_length       | 77.6         |\n",
            "|    mean_reward          | 78.2         |\n",
            "|    num_episodes         | 5            |\n",
            "|    out_of_road          | 1            |\n",
            "|    raw_action           | 0.29335025   |\n",
            "|    route_completion     | 0.207        |\n",
            "|    success_rate         | 0            |\n",
            "|    total_cost           | 1            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 80000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013331781 |\n",
            "|    clip_fraction        | 0.0423       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.68        |\n",
            "|    explained_variance   | -0.00188     |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.29         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    std                  | 0.921        |\n",
            "|    value_loss           | 2.81         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 269      |\n",
            "|    ep_rew_mean     | 16.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 508      |\n",
            "|    iterations      | 16       |\n",
            "|    time_elapsed    | 157      |\n",
            "|    total_timesteps | 80000    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 232          |\n",
            "|    ep_rew_mean          | 17.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 499          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 85000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018314018 |\n",
            "|    clip_fraction        | 0.0726       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -2.66        |\n",
            "|    explained_variance   | 0.048        |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.37         |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00253     |\n",
            "|    std                  | 0.915        |\n",
            "|    value_loss           | 3.27         |\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDvN_9_0NRw4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}